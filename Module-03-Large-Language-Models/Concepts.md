## Week 3 â€“ Day 1

### Session Summary

This session introduced advanced Large Language Model (LLM) concepts and their role in building intelligent AI systems. The discussion covered how LLMs work internally, including transformers, tokens, self-attention, context limitations, and embeddings. The session also explored vector databases, Retrieval Augmented Generation (RAG), hybrid retrieval methods, multimodal processing (text, image, audio, video), and production-level application design using tools and agents.
Additionally, the session emphasized structured outputs using schemas, function calling, SQL integration, prompt engineering, evaluation strategies, regression testing, cost optimization, and commercial AI deployment practices.

### Concepts Covered

#### ðŸ”¹ Introduction & API Infrastructure
- Overview of Module 3 topics
- Specialized API interaction
- API key management
- Proxy usage for secure access
- Cost awareness in API usage

#### ðŸ”¹ How LLMs Work
- Transformers architecture
- Tokens and tokenization
- Self-attention mechanism
- Context window limitations
- Model behavior and scaling

#### ðŸ”¹ Embeddings & Semantic Understanding
- Text embeddings
- Multimodal embeddings
- Topic modeling
- Vector representations of text
- Similarity search concepts

#### ðŸ”¹ Vector Databases
- Purpose of vector databases
- ChromaDB
- LanceDB
- Typesense
- Storing and retrieving embeddings efficiently

#### ðŸ”¹ Retrieval Augmented Generation (RAG)
- RAG architecture
- Context injection
- Hybrid RAG
- Combining retrieval with generation

#### ðŸ”¹ Data Encoding & Media Processing
- Base64 (B64) encoding
- Image processing workflows
- Audio processing basics
- Vision models
- Video analysis using frames

#### ðŸ”¹ Prompt Engineering & Applications
- Prompt engineering techniques
- Sentiment analysis
- Text extraction
- Function calling
- Travel agent use-case example
- Structured outputs using schemas
- SQL database interaction through LLMs

#### ðŸ”¹ Agents & Tools
- Tool usage inside LLM systems
- Agent-based orchestration
- Multi-step reasoning systems

#### ðŸ”¹ Evaluation & Testing
- LLM evaluation (LLM eval)
- YAML-based test cases
- Assertions
- Regression testing
- Performance validation
- Cost-effectiveness strategies
- Commercial AI applications

## Week 3 â€“ Day 2

### Session Summary

This session focused on embeddings, vector databases, hybrid RAG architecture, and implementing Project 1 using similarity search. The discussion covered cost-effective embedding models, sentence transformers, OpenAI embeddings, cosine similarity, and vector mathematics concepts. 

The session also explored multimodal embeddings, chunking strategies, environment variable management, asynchronous API calls using HTTPX, and building a question-answering system using embedding-based retrieval. The day concluded with implementing a top-5 similarity search pipeline using NumPy.

---

### Concepts Covered

#### ðŸ”¹ Embeddings & Similarity
- Text and image embeddings
- Sentence Transformers
- OpenAI embedding models
- Cost-effective embedding strategies
- Cosine similarity
- Dot product
- Vector norm
- Similarity scoring

#### ðŸ”¹ Multimodal Embeddings
- Nomic AI embeddings
- Text + Image similarity
- API key configuration
- JSON-based data exchange
- Python input/output handling

#### ðŸ”¹ Vector Databases & Storage
- Storing embeddings in structured format
- chunks.json structure:
  - ID
  - Source
  - Text
  - Embeddings
- Efficient retrieval workflows
- Hybrid RAG overview

#### ðŸ”¹ Chunking Strategy
- Why chunking is required
- Token limits and context handling
- Fixed-size vs semantic chunking
- Preparing chunks for embedding

#### ðŸ”¹ Environment & Configuration
- Environment variables
- .bashrc configuration
- Secure API key storage
- AI Pipe usage

#### ðŸ”¹ Project 1 Implementation
- Embedding-based retrieval system
- Query embedding generation
- Similarity comparison
- Retrieving most relevant chunks
- Cost-performance optimization
