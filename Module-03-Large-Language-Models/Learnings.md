## Week 3 – Day 1

### Key Learnings

- Understood the internal working of transformer-based LLMs
- Learned how self-attention enables contextual reasoning
- Recognized context window limitations in large models
- Understood how embeddings convert text into vector space
- Learned how vector databases power semantic retrieval
- Gained clarity on RAG and Hybrid RAG architectures
- Understood multimodal AI workflows (text, image, audio, video)
- Learned how structured schemas improve reliability
- Understood how function calling enables real-world automation
- Recognized how agents coordinate tools for complex workflows
- Learned how to evaluate LLM outputs using YAML-based tests
- Understood regression testing and assertion-based validation
- Recognized the importance of cost optimization in production AI
- Gained insight into commercial AI system deployment strategies

## Week 3 – Day 2

### Key Learnings

- Understood how embeddings convert text into numerical vector space
- Learned mathematical foundations of similarity (cosine, dot, norm)
- Gained clarity on multimodal embeddings (text + image)
- Learned practical chunking strategies for large documents
- Understood token limitations and context optimization
- Built an embedding-based retrieval pipeline
- Implemented top-k similarity search using NumPy
- Learned async API handling using HTTPX
- Understood timeout and JSON-safe handling practices
- Recognized importance of environment variable security
- Learned how hybrid RAG improves retrieval quality
- Gained practical exposure to building a mini search engine (Project 1)
